<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <meta name="generator" content="Pelican" />
        <title>Error when restarting Databricks streaming job</title>
        <link rel="stylesheet" href="/theme/css/main.css" />
        <meta name="description" content="This is an error I encountered when I have a Spark Streaming job running on Databricks 6.1. Consider the case I have to update a running streaming..." />
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">Marco Santoni</a></h1>
                <nav><ul>
                    <li><a href="/pages/atacmonitor.html">atacmonitor</a></li>
                    <li><a href="/pages/bookshelf.html">bookshelf</a></li>
                    <li class="active"><a href="/category/posts.html">posts</a></li>
                </ul></nav>
        </header><!-- /#banner -->
<section id="content" class="body">
  <article>
    <header>
      <h1 class="entry-title">
        <a href="/error_restarting_databricks_streaming.html" rel="bookmark"
           title="Permalink to Error when restarting Databricks streaming job">Error when restarting Databricks streaming job</a></h1>
    </header>

    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2020-04-19T18:00:00+02:00">
                Published: Sun 19 April 2020
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/marco-santoni.html">Marco Santoni</a>
        </address>
<p>In <a href="/category/posts.html">posts</a>.</p>

</footer><!-- /.post-info -->      <p>This is an error I encountered when I have a Spark Streaming job running on Databricks 6.1. Consider the case I have to update a running streaming query. Databricks <a href="https://docs.databricks.com/spark/latest/structured-streaming/production.html#configure-jobs-to-restart-streaming-queries-on-failure">recommends</a> to always start (and restart too?) a streaming query on a <strong>new</strong> dedicated cluster. However, in some scenario you might not be able to do so, and you may want to:</p>
<ul>
<li>cancel the job run</li>
<li>update the notebooks</li>
<li>restart the job run</li>
</ul>
<p>By taking these steps, I encountered these error:</p>
<div class="highlight"><pre><span></span><code><span class="n">Concurrent</span><span class="w"> </span><span class="k">update</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="nf">log</span><span class="p">.</span><span class="w"> </span><span class="n">Multiple</span><span class="w"> </span><span class="n">streaming</span><span class="w"> </span><span class="n">jobs</span><span class="w"> </span><span class="n">detected</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="p">...</span><span class="w"></span>

<span class="err">#</span><span class="w"> </span><span class="ow">or</span><span class="w"></span>

<span class="n">Multiple</span><span class="w"> </span><span class="n">streaming</span><span class="w"> </span><span class="n">queries</span><span class="w"> </span><span class="k">are</span><span class="w"> </span><span class="n">concurrently</span><span class="w"> </span><span class="k">using</span><span class="w"> </span><span class="p">...</span><span class="w"> </span><span class="o">[</span><span class="n">checkpoint</span><span class="o">]</span><span class="w"></span>
</code></pre></div>


<p>They did not occur every time I restarted the query, but most of the times. When restarting 2-3 times, the issue was solved and the streaming query run smoothly. By investigating a bit more the error, we found that cancelling a job run via Databricks CLI was not letting the stream query close smoothly. What happened? The running query was not closing cleanly the <a href="https://docs.databricks.com/spark/latest/structured-streaming/production.html#enable-checkpointing">checkpoints</a>. So, when a new job run started, it raised an error because it found a corrupted checkpoint.</p>
<h2>Solution</h2>
<p>You can</p>
<ul>
<li>upgrade do Databricks 6.3 and set <a href="https://docs.databricks.com/release-notes/runtime/6.3.html#improvements">spark.sql.streaming.stopActiveRunOnRestart</a> to true</li>
<li>wait for Databricks 7 to be release where this configuration is enabled by default</li>
</ul>
    </div><!-- /.entry-content -->

  </article>
</section>
        <section id="extras" class="body">
                <div class="social">
                        <h2>social</h2>
                        <ul>

                            <li><a href="https://linkedin.com/in/msantoni">linkedin</a></li>
                            <li><a href="https://twitter.com/mrsantoni">twitter</a></li>
                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="https://getpelican.com/">Pelican</a>, which takes great advantage of <a href="https://www.python.org/">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a href="https://www.smashingmagazine.com/2009/08/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

</body>
</html>